{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo de classificação (S_GROUP_ID_1)\n",
    "\n",
    "A seguir, apresentamos os testes realizados com os modelos de classificação durante esta Sprint. O objetivo desses modelos é prever, após a detecção de uma falha no carro, quais tipos de falhas são mais prováveis de ocorrer. Para isso, cada tipo de falha é abordado por um modelo binário. Nesta Sprint, concentramos nossos esforços na avaliação do desempenho do modelo para a classe \"S_GROUP_ID_1\", buscando identificar o modelo com a melhor performance. Com base nos resultados obtidos, planejamos aplicar os insights e aprimoramentos para os modelos das outras classes existentes.\n",
    "\n",
    "Para conduzir os testes e comparar o desempenho dos diferentes modelos, utilizamos dois conjuntos de dados distintos. O primeiro conjunto de dados não incluiu as informações de torques fornecidas pelo parceiro, enquanto o segundo conjunto incorporou esses dados para treinar e aplicar o modelo. \n",
    "\n",
    "O processo de testes e as análises realizadas são detalhados a seguir, junto com as considerações e conclusões derivadas desses experimentos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM,GRU, Dropout, Dense, Conv1D, MaxPooling1D, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teste sem dados de torque"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A seguir, detalhamos os testes realizados utilizando redes neurais recorrentes LSTM e GRU nos dataframe sem dados de torque. O funcionamento dessas técnicas foi explicado em profundidade na documentação da Sprint 2, onde elas foram aplicadas ao modelo principal. Devido ao seu bom desempenho nessa etapa anterior, decidimos iniciar os testes desta Sprint utilizando essas RNNs como base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# carregamento do dataframe\n",
    "df = pd.read_csv(\"../../data/Merge_Falhas_Resultados.csv\")\n",
    "df[\"S_GROUP_ID_1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converter a coluna para binário\n",
    "df['S_GROUP_ID_1'] = (df['S_GROUP_ID_1'] > 0).astype(int)\n",
    "df['S_GROUP_ID_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separando as features (X) e o target (y)\n",
    "X = df.drop(columns=['S_GROUP_ID_1', 'KNR'])  # 'KNR' é apenas um identificador, então deve ser removido\n",
    "y = df['S_GROUP_ID_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separando em dados de treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converte X_train e X_test para arrays NumPy.\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "\n",
    "# Reestrutura X_train e X_test para ter 3 dimensões.\n",
    "# A nova forma do array será (n_samples, n_features, 1)\n",
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construção do modelo com LSTM\n",
    "model_1 = Sequential()\n",
    "\n",
    "model_1.add(LSTM(50, activation='relu', return_sequences=True, input_shape=(X_train.shape[1], 1)))\n",
    "model_1.add(LSTM(50, activation='relu'))\n",
    "model_1.add(Dense(1))\n",
    "\n",
    "model_1.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinamento do modelo\n",
    "model_1.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prever os dados de teste\n",
    "y_pred_1 = model_1.predict(X_test)\n",
    "\n",
    "# Converter as probabilidades em classes binárias (0 ou 1)\n",
    "y_pred_classes_1 = (y_pred_1 > 0.5).astype(int)\n",
    "\n",
    "# Calcular as principais métricas\n",
    "accuracy_1 = accuracy_score(y_test, y_pred_classes_1)\n",
    "precision_1= precision_score(y_test, y_pred_classes_1)\n",
    "recall_1 = recall_score(y_test, y_pred_classes_1)\n",
    "f1_1 = f1_score(y_test, y_pred_classes_1)\n",
    "\n",
    "print(f\"Accuracy: {accuracy_1:.4f}\")\n",
    "print(f\"Precision: {precision_1:.4f}\")\n",
    "print(f\"Recall: {recall_1:.4f}\")\n",
    "print(f\"F1-Score: {f1_1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"S_GROUP_ID_1\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construção do modelo com GRU\n",
    "model_2 = Sequential()\n",
    "\n",
    "model_2.add(GRU(50, activation='relu', return_sequences=True, input_shape=(X_train.shape[1], 1)))\n",
    "model_2.add(GRU(50, activation='relu'))\n",
    "model_2.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_2.compile(optimizer='adam', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinamento do modelo\n",
    "model_2.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prever os dados de teste\n",
    "y_pred_2 = model_2.predict(X_test)\n",
    "\n",
    "# Converter as probabilidades em classes binárias (0 ou 1)\n",
    "y_pred_classes_2 = (y_pred_2 > 0.5).astype(int)\n",
    "\n",
    "# Calcular as principais métricas\n",
    "accuracy_2 = accuracy_score(y_test, y_pred_classes_2)\n",
    "precision_2 = precision_score(y_test, y_pred_classes_2)\n",
    "recall_2 = recall_score(y_test, y_pred_classes_2)\n",
    "f1_2 = f1_score(y_test, y_pred_classes_2)\n",
    "\n",
    "print(f\"Accuracy: {accuracy_2:.4f}\")\n",
    "print(f\"Precision: {precision_2:.4f}\")\n",
    "print(f\"Recall: {recall_2:.4f}\")\n",
    "print(f\"F1-Score: {f1_2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com base nos resultados obtidos, observamos que tanto os modelos LSTM quanto GRU apresentaram boa performance em termos de recall ao utilizar os dados de torque. No entanto, as demais métricas, como a acurácia, não tiveram o mesmo desempenho, o que nos leva a focar em melhorias nessas áreas. A próxima etapa envolve realizar testes com os dados sem torque e, em seguida, comparar os resultados dos modelos treinados com os dois conjuntos de dados. Isso nos permitirá decidir se devemos ou não manter os dados de torque e, a partir dessa decisão, testar novas técnicas para otimizar o modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teste com dados de torque"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A seguir, detalhamos os testes realizados utilizando redes neurais recorrentes LSTM e GRU nos dataframe com dados de torque. O funcionamento dessas técnicas foi explicado em profundidade na documentação da Sprint 2, onde elas foram aplicadas ao modelo principal. Devido ao seu bom desempenho nessa etapa anterior, decidimos iniciar os testes desta Sprint utilizando essas RNNs como base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# carregando o dataframe\n",
    "df2 = pd.read_csv(\"../../data/df_torques_falhas.csv\")\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converter a coluna para binário\n",
    "df2['S_GROUP_ID_1'] = (df2['S_GROUP_ID_1'] > 0).astype(int)\n",
    "df2['S_GROUP_ID_1']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Excluindo as cplunas com dados NaN\n",
    "df2 = df2.dropna()\n",
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separando as features (X) e o target (y)\n",
    "X2 = df2.drop(columns=['S_GROUP_ID_1', 'KNR'])  # 'KNR' é apenas um identificador, então deve ser removido\n",
    "y2 = df2['S_GROUP_ID_1']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separando em dados de treino e teste\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converte X_train e X_test para arrays NumPy, caso ainda não sejam.\n",
    "X2_train = np.array(X2_train)\n",
    "X2_test = np.array(X2_test)\n",
    "# Reestrutura X_train e X_test para ter 3 dimensões.\n",
    "# A nova forma do array será (n_samples, n_features, 1)\n",
    "X2_train = X2_train.reshape((X2_train.shape[0], X2_train.shape[1], 1))\n",
    "X2_test = X2_test.reshape((X2_test.shape[0], X2_test.shape[1], 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construção do modelo com LSTM\n",
    "model_1_2 = Sequential()\n",
    "\n",
    "model_1_2.add(LSTM(50, activation='relu', return_sequences=True, input_shape=(X2_train.shape[1], 1)))\n",
    "model_1_2.add(LSTM(50, activation='relu'))\n",
    "model_1_2.add(Dense(1))\n",
    "\n",
    "model_1_2.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinamento do modelo\n",
    "model_1_2.fit(X2_train, y2_train, epochs=100, batch_size=32, validation_data=(X2_test, y2_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prever os dados de teste\n",
    "y_pred_1_2 = model_1_2.predict(X2_test)\n",
    "\n",
    "# Converter as probabilidades em classes binárias (0 ou 1)\n",
    "y_pred_classes_1_2 = (y_pred_1_2 > 0.5).astype(int)\n",
    "\n",
    "# Calcular as principais métricas\n",
    "accuracy = accuracy_score(y2_test, y_pred_classes_1_2)\n",
    "precision = precision_score(y2_test, y_pred_classes_1_2)\n",
    "recall = recall_score(y2_test, y_pred_classes_1_2)\n",
    "f1 = f1_score(y2_test, y_pred_classes_1_2)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construção do modelo com GRU\n",
    "model_2_2 = Sequential()\n",
    "\n",
    "model_2_2.add(GRU(50, activation='relu', return_sequences=True, input_shape=(X2_train.shape[1], 1)))\n",
    "model_2_2.add(GRU(50, activation='relu'))\n",
    "model_2_2.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_2_2.compile(optimizer='adam', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinamento do modelo\n",
    "model_2_2.fit(X2_train, y2_train, epochs=100, batch_size=32, validation_data=(X2_test, y2_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prever os dados de teste\n",
    "y_pred_2_2 = model_2_2.predict(X2_test)\n",
    "\n",
    "# Converter as probabilidades em classes binárias (0 ou 1)\n",
    "y_pred_classes_2_2 = (y_pred_2_2 > 0.5).astype(int)\n",
    "\n",
    "# Calcular as principais métricas\n",
    "accuracy = accuracy_score(y2_test, y_pred_classes_2_2)\n",
    "precision = precision_score(y2_test, y_pred_classes_2_2)\n",
    "recall = recall_score(y2_test, y_pred_classes_2_2)\n",
    "f1 = f1_score(y2_test, y_pred_classes_2_2)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com base nos resultados obtidos, observamos que tanto os modelos LSTM quanto GRU tiveram um bom desempenho em termos de recall ao utilizar os dados de torque. No entanto, outras métricas, como a acurácia, não apresentaram o mesmo nível de performance, tanto com os dados de torque quanto com o dataframe sem esses dados. Ao comparar os dois dataframes, notamos que ambos tiveram um desempenho muito similar, o que indica que ambos podem ser utilizados nos modelos. No entanto, para os próximos testes, optamos por trabalhar com o dataframe que inclui os dados de torque, pois ele apresentou métricas mais consistentes e fornece um conjunto mais rico de features.\n",
    "\n",
    "Para melhorar as métricas observadas, aplicaremos as seguintes técnicas:\n",
    "\n",
    "- Diferentes testes de balanceamento \n",
    "- Teste de outros tipos de modelos.\n",
    "- Revisão e aprimoramento do tratamento dos dados\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Últimos teste realizados nessa Sprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Ainda essa Sprint, realizamos testes com o balanceamento por undersampling com clusterização, utilizando os centróides de cada cluster. Utilizamos essa tecnica a partir do código abaixo, utilizando X2_balanced e y2_balanced para treinar e aplicar os modelos GRU e LSTM. Entretanto, as métricas diminuiram drasticamente, indicando que devem ser realizadas melhorias ou na forma de balanceamento, ou no tramaento dos dados que estamos utilizando. Para averiguar, basta utilizar o código a seguir antes do treinamento e aplicação dos modelos na etapa de testes com dados de torque."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separando as classes majoritária e minoritária com base no target y2\n",
    "X2_majority = X2[y2 == 0]\n",
    "X2_minority = X2[y2 == 1]\n",
    "\n",
    "# Definindo o número de clusters como o tamanho da classe minoritária\n",
    "n_clusters = len(X2_minority)\n",
    "\n",
    "# Aplicando o K-Means à classe majoritária\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=1)\n",
    "kmeans.fit(X2_majority)\n",
    "\n",
    "# Pegando os centróides dos clusters\n",
    "X2_majority_centroids = kmeans.cluster_centers_\n",
    "\n",
    "# Combinando os centróides com a classe minoritária\n",
    "X2_balanced = np.vstack((X2_majority_centroids, X2_minority))\n",
    "y2_balanced = np.hstack((np.zeros(len(X2_majority_centroids)), np.ones(len(X2_minority))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Além disso, tentamos também aplicar a seguinte rede neural convolucional, para testar a performance do modelo. Infelizmente, não obtivemos resultados tão positivos quanto os dos modelo GRU e LSTM, porém, pretendemos focar em pesquisar e aplicar novos tipos de rede neural convolucional que possam se adequar melhor ao problema e trazer melhores resultados na próxima Sprint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir o modelo CNN\n",
    "model_3 = Sequential()\n",
    "\n",
    "# Primeira camada convolucional\n",
    "model_3.add(Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(X2_train.shape[1], 1)))\n",
    "model_3.add(MaxPooling1D(pool_size=2))\n",
    "model_3.add(Dropout(0.3))\n",
    "\n",
    "# Segunda camada convolucional\n",
    "model_3.add(Conv1D(filters=64, kernel_size=2, activation='relu'))\n",
    "model_3.add(MaxPooling1D(pool_size=2))\n",
    "model_3.add(Dropout(0.3))\n",
    "\n",
    "# Flatten para converter dados 2D em 1D\n",
    "model_3.add(Flatten())\n",
    "\n",
    "# Camada totalmente conectada\n",
    "model_3.add(Dense(64, activation='relu'))\n",
    "model_3.add(Dropout(0.5))\n",
    "\n",
    "# Camada de saída para classificação binária\n",
    "model_3.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compilação do modelo\n",
    "model_3.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinamento do modelo\n",
    "model_3.fit(X2_train, y2_train, epochs=100, batch_size=32, validation_data=(X2_test, y2_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prever os dados de teste\n",
    "y_pred_3 = model_3.predict(X2_test)\n",
    "\n",
    "# Converter as probabilidades em classes binárias (0 ou 1)\n",
    "y_pred_classes_3 = (y_pred_3 > 0.5).astype(int)\n",
    "\n",
    "# Calcular as principais métricas\n",
    "accuracy = accuracy_score(y2_test, y_pred_classes_3)\n",
    "precision = precision_score(y2_test, y_pred_classes_3)\n",
    "recall = recall_score(y2_test, y_pred_classes_3)\n",
    "f1 = f1_score(y2_test, y_pred_classes_3)\n",
    "\n",
    "# Exibir as métricas\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-Score: {f1:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
